{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcODEFPA2H48",
        "outputId": "2d82aea0-c20f-4a52-c702-11e53450e3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.25.11)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.11.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjLem17KlFiv"
      },
      "source": [
        "## Data Pre-processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vDTpUW9ViV_",
        "outputId": "9ee9b698-12f7-4be2-8f00-1a995483b62d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version is:  1.11.0+cu113\n",
            "You are using:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Pytorch version is: \", torch.__version__)\n",
        "print(\"You are using: \", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "085UtXq2Vlp-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "from typing import Tuple, List\n",
        "\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "\n",
        "SEED = 1\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "class Placeholder:\n",
        "    @property\n",
        "    def DO(self):\n",
        "        raise NotImplementedError(\"You haven't yet implemented this part of the assignment yet\")\n",
        "\n",
        "TO = Placeholder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24N213sTVoR7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! python -m spacy download en\n",
        "! python -m spacy download de\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "de_tokenizer = get_tokenizer('spacy', language='de')\n",
        "en_tokenizer = get_tokenizer('spacy', language='en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCz4ENa4VrVf",
        "outputId": "2af0e155-73e2-4703-eaa5-db472947abd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/datapipes/iter/combining.py:181: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  \"the buffer and each child DataPipe will read from the start again.\", UserWarning)\n"
          ]
        }
      ],
      "source": [
        "train_data, valid_data, test_data = Multi30k()\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "de_generator = (de_tokenizer(pair[0].strip().lower()) for pair in Multi30k(split=\"train\"))\n",
        "specials = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "de_vocab = build_vocab_from_iterator(de_generator, specials=specials, min_freq=2)\n",
        "en_generator = (en_tokenizer(pair[1].strip().lower()) for pair in Multi30k(split=\"train\"))\n",
        "en_vocab = build_vocab_from_iterator(en_generator, specials=specials, min_freq=2)\n",
        "\n",
        "for vocab in (de_vocab, en_vocab):\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5CDFXSEV_h-",
        "outputId": "737e9d11-51b4-4b05-f59a-045f74d098b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/datapipes/iter/combining.py:181: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  \"the buffer and each child DataPipe will read from the start again.\", UserWarning)\n"
          ]
        }
      ],
      "source": [
        "BOS_IDX = de_vocab['<bos>']\n",
        "EOS_IDX = de_vocab['<eos>']\n",
        "\n",
        "def data_process(raw_dataset) -> List[Tuple[Tensor, Tensor]]:\n",
        "    ret = []\n",
        "    for pair in raw_dataset: \n",
        "      # lower case and strip both German and English tokens in each sentence pair \n",
        "      d_tokens = de_tokenizer(pair[0].strip().lower()) \n",
        "      e_tokens = de_tokenizer(pair[1].strip().lower()) \n",
        "\n",
        "      # add <bos> and <eos> tokens to both German and English sentences \n",
        "      d_tokens.insert(0, '<bos>')\n",
        "      d_tokens.append('<eos>')\n",
        "      e_tokens.insert(0, '<bos>')\n",
        "      e_tokens.append('<eos>') \n",
        "\n",
        "      # get encoded tensor tuple from vocabs  \n",
        "      d_tens = torch.tensor([de_vocab[token] for token in d_tokens], dtype=torch.long)\n",
        "      e_tens = torch.tensor([en_vocab[token] for token in e_tokens], dtype=torch.long)\n",
        "      tup = (d_tens, e_tens)\n",
        "\n",
        "      # add tensor tuple to list \n",
        "      ret.append(tup) \n",
        "\n",
        "    return ret \n",
        "\n",
        "train_data, valid_data, test_data = Multi30k()\n",
        "train_data_processed = data_process(train_data)\n",
        "valid_data_processed = data_process(valid_data)\n",
        "test_data_processed = data_process(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdnydY3EWClU",
        "outputId": "5e4950f6-caef-44cc-d536-86e6d4fe77f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos> zwei junge weiße männer sind im freien in der nähe vieler büsche . <eos>\n",
            "<bos> two young , white males are outside near many bushes . <eos>\n"
          ]
        }
      ],
      "source": [
        "# Making sure German isn't reversed\n",
        "de_itos = de_vocab.get_itos()\n",
        "en_itos = en_vocab.get_itos()\n",
        "de_encoded, en_encoded = train_data_processed[0]\n",
        "print(\" \".join([de_itos[item] for item in de_encoded]))\n",
        "print(\" \".join([en_itos[item] for item in en_encoded]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RVfu7JyV8nf"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "PAD_IDX = de_vocab['<pad>']\n",
        "\n",
        "def collate_fn(data_batch) -> Tuple[Tensor, Tensor]: \n",
        "    # initialize lists to be added to returned tuple \n",
        "    de_batch = [] \n",
        "    en_batch = [] \n",
        "    for pair in data_batch: \n",
        "      de = pair[0]\n",
        "      en = pair[1] \n",
        "      # add indices/lengths to corresponding batches/list\n",
        "      # de_tens = torch.cat([torch.tensor([BOS_IDX]), de, torch.tensor([EOS_IDX])], 0)\n",
        "      # en_tens = torch.cat([torch.tensor([BOS_IDX]), en, torch.tensor([EOS_IDX])], 0)\n",
        "      de_batch.append(de)\n",
        "      en_batch.append(en)\n",
        "    # pad sequences \n",
        "    # send to GPU \n",
        "    de_batch = torch.tensor(pad_sequence(de_batch, padding_value=PAD_IDX, batch_first=True)).to(DEVICE) \n",
        "    en_batch = torch.tensor(pad_sequence(en_batch, padding_value=PAD_IDX, batch_first=True)).to(DEVICE) \n",
        "    ret = (de_batch, en_batch) \n",
        "\n",
        "    return ret \n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_data_processed,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "valid_dl = DataLoader(\n",
        "    valid_data_processed,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "test_dl = DataLoader(\n",
        "    test_data_processed,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzj1wiqXOR9P"
      },
      "source": [
        "# Transformer Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQImKA7dtCHg"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model: int,\n",
        "        max_len: int = 512,\n",
        "        dropout: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.full((max_len, d_model), -100.0)\n",
        "        pos = torch.arange(max_len).unsqueeze(1)\n",
        "        indxs = torch.arange(d_model // 2).unsqueeze(0) * 2\n",
        "        denom = 10000 ** (indxs / d_model)\n",
        "        pe[:, ::2] = torch.sin(pos / denom)\n",
        "        pe[:, 1::2] = torch.cos(pos / denom)\n",
        "        self.pe = pe.unsqueeze(0).to(DEVICE)  \n",
        "\n",
        "    def forward(self, embed):\n",
        "        return self.dropout(embed + self.pe[:, embed.size(1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYVwqo9BtG12"
      },
      "outputs": [],
      "source": [
        "LOG_PROB_ZERO = -1e9\n",
        "\n",
        "\n",
        "def get_padding_mask(seq, pad_idx=0, dtype=torch.float32):\n",
        "    mask = (seq == pad_idx).type(dtype)\n",
        "    mask *= LOG_PROB_ZERO\n",
        "    mask.unsqueeze_(1).unsqueeze_(1)\n",
        "    return mask.to(DEVICE)\n",
        "\n",
        "\n",
        "def get_lookahead_mask(n):\n",
        "    mask = torch.full((n, n), -LOG_PROB_ZERO)\n",
        "    mask = torch.tril(mask)\n",
        "    mask += LOG_PROB_ZERO\n",
        "    mask = mask.unsqueeze(0)  \n",
        "    return mask.to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4eIU4h5g0G0"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None): \n",
        "    att = torch.matmul(q, k.transpose(-2,-1))/math.sqrt(k.size(-1)) \n",
        "    if mask is not None: \n",
        "      att += mask \n",
        "    att = F.softmax(att, dim=-1) \n",
        "    ret = torch.matmul(att, v) \n",
        "    return ret, att"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0cktYAVg0h7"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % n_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.depth = d_model // n_heads\n",
        "\n",
        "        self.wk = nn.Linear(d_model, d_model)\n",
        "        self.wv = nn.Linear(d_model, d_model)\n",
        "        self.wq = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def split_heads(self, x): \n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        x = x.reshape(batch_size, seq_length, self.n_heads, self.depth)\n",
        "        x = x.transpose(1,2) \n",
        "        return x \n",
        "\n",
        "    def merge_heads(self, x): \n",
        "        batch_size, _, seq_length, d_model = x.shape \n",
        "        x = x.transpose(1,2) \n",
        "        x = x.reshape(x.shape[0], x.shape[1], -1) \n",
        "        return x  \n",
        "\n",
        "    def forward(self, q, k, v, masks):\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "        q = self.wq(q)\n",
        "        k = self.split_heads(k)\n",
        "        v = self.split_heads(v)\n",
        "        q = self.split_heads(q)\n",
        "        attn, attn_weights = scaled_dot_product_attention(q, k, v, masks)\n",
        "        attn = self.merge_heads(attn)\n",
        "        out = self.fc(attn)\n",
        "        return out, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvqPDmGgg2Yq"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff), nn.ReLU(), nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.ff_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x, padding_mask): \n",
        "        identity = x\n",
        "        x, _ = self.mha(x, x, x, padding_mask)\n",
        "        x = self.mha_dropout(x)\n",
        "        x += identity\n",
        "        x = self.layer_norm1(x)\n",
        "\n",
        "        x = self.ff(x) \n",
        "        x = self.ff_dropout(x)\n",
        "        x += identity \n",
        "        x = self.layer_norm2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWVwcI1Kg3Lx"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, d_ff, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                EncoderLayer(num_heads, d_model, d_ff, dropout)\n",
        "                for _ in range(n_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x, padding_mask): \n",
        "        assert x.shape[2] == self.d_model\n",
        "        assert x.shape[0] <= BATCH_SIZE\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, padding_mask)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1X1SXAwhCjF"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.masked_mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.masked_mha_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff), nn.ReLU(), nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.ff_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm3 = nn.LayerNorm(d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x, enc_output, lookahead_mask, padding_mask): \n",
        "        # layer 1 - masked multi-head attention \n",
        "        identity = x \n",
        "        x, _ = self.masked_mha(x, x, x, lookahead_mask)\n",
        "        x = self.masked_mha_dropout(x)\n",
        "        x += identity\n",
        "        x = self.layer_norm1(x)\n",
        "\n",
        "        # layer 2 - multi-head attention\n",
        "        # get queries from previous decoder layer \n",
        "        # get keys and values from encoder output \n",
        "        identity = x \n",
        "        k = enc_output \n",
        "        v = enc_output \n",
        "        x, _ = self.mha(x, k, v, padding_mask)\n",
        "        x = self.mha_dropout(x)\n",
        "        x += identity \n",
        "        x = self.layer_norm2(x)\n",
        "\n",
        "        # layer 3 - feedforward \n",
        "        identity = x \n",
        "        x = self.ff(x)\n",
        "        x = self.ff_dropout(x)\n",
        "        x += identity \n",
        "        x = self.layer_norm3(x)\n",
        "        return x \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPkKmt8WyYhT"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, d_ff, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                DecoderLayer(num_heads, d_model, d_ff, dropout)\n",
        "                for _ in range(n_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x, enc_output, lookahead_mask, padding_mask): \n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_output, lookahead_mask, padding_mask)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjWxSEdKzJ9z"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        num_heads,\n",
        "        d_model,\n",
        "        d_ff,\n",
        "        n_enc_layers,\n",
        "        n_dec_layers,\n",
        "        max_len=1024,\n",
        "        pad_idx=0,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(num_heads, d_model, d_ff, n_enc_layers, dropout)\n",
        "        self.decoder = Decoder(num_heads, d_model, d_ff, n_dec_layers, dropout)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.in_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.out_linear = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.pad_idx = pad_idx\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        input_padding_mask, lookahead_mask = self._get_masks(x, y) \n",
        "\n",
        "        x = self.in_embedding(x) \n",
        "        x = self.pos_encoding(x) \n",
        "        enc_output = self.encoder(x, input_padding_mask)\n",
        "        \n",
        "        y = self.tgt_embedding(y)\n",
        "        y = self.pos_encoding(y)\n",
        "        dec_output = self.decoder(y, enc_output, lookahead_mask, input_padding_mask) \n",
        "        out = self.out_linear(dec_output)\n",
        "        return out\n",
        "\n",
        "    def _get_masks(self, x, y):\n",
        "        input_padding_mask = get_padding_mask(x, pad_idx=self.pad_idx)\n",
        "        target_padding_mask = get_padding_mask(y, pad_idx=self.pad_idx)\n",
        "        lookahead_mask = get_lookahead_mask(y.shape[-1])\n",
        "        lookahead_mask = torch.minimum(target_padding_mask, lookahead_mask)\n",
        "        return input_padding_mask, lookahead_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt5rWPx1znlY"
      },
      "outputs": [],
      "source": [
        "NUM_HEADS = 8\n",
        "D_MODEL = 256\n",
        "D_FF = 1024\n",
        "N_ENC_LAYERS = 6\n",
        "N_DEC_LAYERS = 6\n",
        "\n",
        "model = Transformer(\n",
        "    len(de_vocab), \n",
        "    len(en_vocab), \n",
        "    num_heads=NUM_HEADS,\n",
        "    d_model=D_MODEL,\n",
        "    d_ff=D_FF,\n",
        "    n_enc_layers=N_ENC_LAYERS,\n",
        "    n_dec_layers=N_DEC_LAYERS,\n",
        ").to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "PAD_IDX = de_vocab[\"<pad>\"]\n",
        "assert PAD_IDX == en_vocab[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCXB9UM_73kB"
      },
      "outputs": [],
      "source": [
        "class AdamWrapper:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "    \n",
        "    def zero_grad(self, *args, **kwargs):\n",
        "        return self.optimizer.zero_grad(*args, **kwargs)\n",
        "\n",
        "optimizer = AdamWrapper(D_MODEL, 1, 2000,\n",
        "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaaYSACNzyVf"
      },
      "outputs": [],
      "source": [
        "# training loop \n",
        "def train(model, train_dl, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, (src, tgt) in enumerate(train_dl):\n",
        "        model_sees = tgt[:, :-1]\n",
        "        loss_sees = tgt[:, 1:]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(src, model_sees)\n",
        "        loss = criterion(\n",
        "            logits.reshape(-1, logits.shape[-1]), loss_sees.reshape(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(train_dl)\n",
        "\n",
        "\n",
        "def evaluate(model, val_dl, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in val_dl:\n",
        "            model_sees = tgt[:, :-1]\n",
        "            loss_sees = tgt[:, 1:]\n",
        "            logits = model(src, model_sees)\n",
        "            loss = criterion(\n",
        "                logits.reshape(-1, logits.shape[-1]), loss_sees.reshape(-1)\n",
        "            )\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEgdRTus0Lzd",
        "outputId": "5c315ffa-80fd-400f-b96c-76b49ac6cea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 33s\n",
            "\tTrain Loss: 6.097 | Train PPL: 444.405\n",
            "\t Val. Loss: 4.329 |  Val. PPL:  75.853\n",
            "Epoch: 02 | Time: 0m 33s\n",
            "\tTrain Loss: 3.900 | Train PPL:  49.383\n",
            "\t Val. Loss: 3.351 |  Val. PPL:  28.538\n",
            "Epoch: 03 | Time: 0m 33s\n",
            "\tTrain Loss: 3.207 | Train PPL:  24.695\n",
            "\t Val. Loss: 2.829 |  Val. PPL:  16.933\n",
            "Epoch: 04 | Time: 0m 33s\n",
            "\tTrain Loss: 2.714 | Train PPL:  15.083\n",
            "\t Val. Loss: 2.478 |  Val. PPL:  11.914\n",
            "Epoch: 05 | Time: 0m 33s\n",
            "\tTrain Loss: 2.358 | Train PPL:  10.568\n",
            "\t Val. Loss: 2.242 |  Val. PPL:   9.409\n"
          ]
        }
      ],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 5 \n",
        "CLIP = 10\n",
        "SAVE_DIR = \"models\"\n",
        "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, \"cpsc477_hw4_transformer.pt\")\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "if not os.path.isdir(f\"{SAVE_DIR}\"):\n",
        "    os.makedirs(f\"{SAVE_DIR}\")\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_dl, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_dl, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
        "    print(\n",
        "        f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\"\n",
        "    )\n",
        "    print(\n",
        "        f\"\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI7mlQOGAVD6"
      },
      "outputs": [],
      "source": [
        "def translate(\n",
        "    model, de_vocab, de_tokenizer, en_vocab, sentence, max_length=512\n",
        "):\n",
        "    def process_sentence(sentence, vocab, tokenizer):\n",
        "        tokens = tokenizer(sentence.strip().lower())\n",
        "        return torch.tensor(\n",
        "            [BOS_IDX] + [vocab[token] for token in tokens] + [EOS_IDX],\n",
        "            dtype=torch.long,\n",
        "        )\n",
        "    encoded_input = process_sentence(sentence, de_vocab, de_tokenizer)\n",
        "    encoded_input = encoded_input.unsqueeze(0).to(DEVICE) \n",
        "    output = torch.full((1, 1), BOS_IDX).type(torch.long).to(DEVICE)\n",
        "    model.eval()\n",
        "    end_slice_i = None\n",
        "    for _ in range(max_length - 1):\n",
        "        logits = model(encoded_input, output)\n",
        "        next_id = torch.argmax(logits[:, -1, :], dim=-1)\n",
        "        next_id.unsqueeze_(0)\n",
        "        output = torch.cat((output, next_id), dim=1)\n",
        "        if next_id == EOS_IDX:\n",
        "            end_slice_i = -1\n",
        "            break\n",
        "    output.squeeze_(0) \n",
        "    output = output.tolist()\n",
        "    tokens = en_vocab.lookup_tokens(output[1:end_slice_i])\n",
        "    return \" \".join(tokens) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ9JKvBKArsY",
        "outputId": "d3246aa7-4b97-4e52-ecf5-ec002276edbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/datapipes/iter/combining.py:181: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  \"the buffer and each child DataPipe will read from the start again.\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German: Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\n",
            "Ground truth: A man in an orange hat starring at something.\n",
            "Translation: a man with an orange hat , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , and a man with a <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> hat <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "\n",
            "German: Ein Boston Terrier läuft über saftig-grünes Gras vor einem weißen Zaun.\n",
            "Ground truth: A Boston Terrier is running on lush green grass in front of a white fence.\n",
            "Translation: a dog runs across a white fence in front of a fence .\n",
            "\n",
            "German: Ein Mädchen in einem Karateanzug bricht einen Stock mit einem Tritt.\n",
            "Ground truth: A girl in karate uniform breaking a stick with a front kick.\n",
            "Translation: a girl with a stick and a girl with a stick in a <unk> .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_data = Multi30k(split=\"test\")\n",
        "\n",
        "for _, (de, en) in zip(range(3), test_data):\n",
        "    translated = translate(\n",
        "    model,\n",
        "    de_vocab,\n",
        "    de_tokenizer,\n",
        "    en_vocab,\n",
        "    de\n",
        "    )\n",
        "    print(f\"German: {de.strip()}\")\n",
        "    print(f\"Ground truth: {en.strip()}\")\n",
        "    print(f\"Translation: {translated}\")\n",
        "    print(\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Transformer_Machine_Translation_2022.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}